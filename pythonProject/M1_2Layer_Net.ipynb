{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-24T21:34:05.088253400Z",
     "start_time": "2024-02-24T21:34:04.903239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "select Open ,High ,Low ,Close ,\"Adj Close\" ,Volume ,MACD_12_26_9 ,MACDh_12_26_9 ,MACDs_12_26_9 ,RSI_14 ,\"BBL_5_2.0\" ,\"BBM_5_2.0\" ,\"BBU_5_2.0\" ,\"BBB_5_2.0\" ,\"BBP_5_2.0\" ,OBV ,SMA_20 ,EMA_50 ,STOCHk_14_3_3 ,STOCHd_14_3_3 ,ADX_14 ,DMP_14 ,DMN_14 ,AD ,STDEV_30 ,VWAP_D ,PV_DERIVATIVE ,Y_CLOSE5_MIN from STOCK_DAILY WHERE ticker='TSLA'\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such column: VWAP_D\n[SQL: select Open ,High ,Low ,Close ,\"Adj Close\" ,Volume ,MACD_12_26_9 ,MACDh_12_26_9 ,MACDs_12_26_9 ,RSI_14 ,\"BBL_5_2.0\" ,\"BBM_5_2.0\" ,\"BBU_5_2.0\" ,\"BBB_5_2.0\" ,\"BBP_5_2.0\" ,OBV ,SMA_20 ,EMA_50 ,STOCHk_14_3_3 ,STOCHd_14_3_3 ,ADX_14 ,DMP_14 ,DMN_14 ,AD ,STDEV_30 ,VWAP_D ,PV_DERIVATIVE ,Y_CLOSE5_MIN from STOCK_DAILY WHERE ticker='TSLA']\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1969\u001B[0m, in \u001B[0;36mConnection._exec_single_context\u001B[1;34m(self, dialect, context, statement, parameters)\u001B[0m\n\u001B[0;32m   1968\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evt_handled:\n\u001B[1;32m-> 1969\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdialect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_execute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1970\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[0;32m   1971\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1973\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_events \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine\u001B[38;5;241m.\u001B[39m_has_events:\n",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sqlalchemy\\engine\\default.py:922\u001B[0m, in \u001B[0;36mDefaultDialect.do_execute\u001B[1;34m(self, cursor, statement, parameters, context)\u001B[0m\n\u001B[0;32m    921\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m, cursor, statement, parameters, context\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 922\u001B[0m     \u001B[43mcursor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mOperationalError\u001B[0m: no such column: VWAP_D",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 75\u001B[0m\n\u001B[0;32m     71\u001B[0m query \u001B[38;5;241m=\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\u001B[38;5;124mselect Open ,High ,Low ,Close ,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAdj Close\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m ,Volume ,MACD_12_26_9 ,MACDh_12_26_9 ,MACDs_12_26_9 ,RSI_14 ,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBBL_5_2.0\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m ,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBBM_5_2.0\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m ,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBBU_5_2.0\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m ,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBBB_5_2.0\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m ,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBBP_5_2.0\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m ,OBV ,SMA_20 ,EMA_50 ,STOCHk_14_3_3 ,STOCHd_14_3_3 ,ADX_14 ,DMP_14 ,DMN_14 ,AD ,STDEV_30 ,VWAP_D ,PV_DERIVATIVE ,Y_CLOSE5_MIN from STOCK_DAILY WHERE ticker=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTSLA\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(query)\n\u001B[1;32m---> 75\u001B[0m all_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mSqliteDataSet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28mprint\u001B[39m(all_dataset\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__len__\u001B[39m())\n\u001B[0;32m     79\u001B[0m train_set, test_set \u001B[38;5;241m=\u001B[39m T\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mrandom_split(all_dataset,[\u001B[38;5;241m650\u001B[39m,\u001B[38;5;241m49\u001B[39m])\n",
      "Cell \u001B[1;32mIn[2], line 18\u001B[0m, in \u001B[0;36mSqliteDataSet.__init__\u001B[1;34m(self, sqlite_rul, query, transform)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine \u001B[38;5;241m=\u001B[39m sqlalchemy\u001B[38;5;241m.\u001B[39mcreate_engine(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msqlite:///D:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124msqlite\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mfinance.db\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;241m=\u001B[39m transform\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult_set \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_sql_query\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdropna()  \n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresult_set\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[0;32m     20\u001B[0m X_columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOpen\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHigh\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLow\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClose\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAdj Close\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVolume\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMACD_12_26_9\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMACDh_12_26_9\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMACDs_12_26_9\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRSI_14\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBBL_5_2.0\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBBM_5_2.0\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBBU_5_2.0\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBBB_5_2.0\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBBP_5_2.0\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mOBV\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSMA_20\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEMA_50\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTOCHk_14_3_3\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTOCHd_14_3_3\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mADX_14\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDMP_14\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDMN_14\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAD\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSTDEV_30\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVWAP_D\u001B[39m\u001B[38;5;124m'\u001B[39m ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPV_DERIVATIVE\u001B[39m\u001B[38;5;124m'\u001B[39m ]\n",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\sql.py:469\u001B[0m, in \u001B[0;36mread_sql_query\u001B[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001B[0m\n\u001B[0;32m    466\u001B[0m     dtype_backend \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# type: ignore[assignment]\u001B[39;00m\n\u001B[0;32m    468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pandasSQL_builder(con) \u001B[38;5;28;01mas\u001B[39;00m pandas_sql:\n\u001B[1;32m--> 469\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpandas_sql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_query\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    470\u001B[0m \u001B[43m        \u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    471\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    472\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    473\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoerce_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcoerce_float\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    474\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    475\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\sql.py:1738\u001B[0m, in \u001B[0;36mSQLDatabase.read_query\u001B[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001B[0m\n\u001B[0;32m   1681\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_query\u001B[39m(\n\u001B[0;32m   1682\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1683\u001B[0m     sql: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1690\u001B[0m     dtype_backend: DtypeBackend \u001B[38;5;241m|\u001B[39m Literal[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1691\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Iterator[DataFrame]:\n\u001B[0;32m   1692\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1693\u001B[0m \u001B[38;5;124;03m    Read SQL query into a DataFrame.\u001B[39;00m\n\u001B[0;32m   1694\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1736\u001B[0m \n\u001B[0;32m   1737\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1738\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1739\u001B[0m     columns \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mkeys()\n\u001B[0;32m   1741\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\sql.py:1562\u001B[0m, in \u001B[0;36mSQLDatabase.execute\u001B[1;34m(self, sql, params)\u001B[0m\n\u001B[0;32m   1560\u001B[0m args \u001B[38;5;241m=\u001B[39m [] \u001B[38;5;28;01mif\u001B[39;00m params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m [params]\n\u001B[0;32m   1561\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sql, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcon\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexec_driver_sql\u001B[49m\u001B[43m(\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1563\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcon\u001B[38;5;241m.\u001B[39mexecute(sql, \u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1778\u001B[0m, in \u001B[0;36mConnection.exec_driver_sql\u001B[1;34m(self, statement, parameters, execution_options)\u001B[0m\n\u001B[0;32m   1773\u001B[0m execution_options \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_execution_options\u001B[38;5;241m.\u001B[39mmerge_with(\n\u001B[0;32m   1774\u001B[0m     execution_options\n\u001B[0;32m   1775\u001B[0m )\n\u001B[0;32m   1777\u001B[0m dialect \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdialect\n\u001B[1;32m-> 1778\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1779\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1780\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdialect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecution_ctx_cls\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_statement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1781\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1782\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1783\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexecution_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1784\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1785\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistilled_parameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1786\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1788\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1848\u001B[0m, in \u001B[0;36mConnection._execute_context\u001B[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001B[0m\n\u001B[0;32m   1843\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exec_insertmany_context(\n\u001B[0;32m   1844\u001B[0m         dialect,\n\u001B[0;32m   1845\u001B[0m         context,\n\u001B[0;32m   1846\u001B[0m     )\n\u001B[0;32m   1847\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1848\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_exec_single_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1849\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdialect\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\n\u001B[0;32m   1850\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1988\u001B[0m, in \u001B[0;36mConnection._exec_single_context\u001B[1;34m(self, dialect, context, statement, parameters)\u001B[0m\n\u001B[0;32m   1985\u001B[0m     result \u001B[38;5;241m=\u001B[39m context\u001B[38;5;241m.\u001B[39m_setup_result_proxy()\n\u001B[0;32m   1987\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1988\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_dbapi_exception\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1989\u001B[0m \u001B[43m        \u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[0;32m   1990\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1992\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2343\u001B[0m, in \u001B[0;36mConnection._handle_dbapi_exception\u001B[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001B[0m\n\u001B[0;32m   2341\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m should_wrap:\n\u001B[0;32m   2342\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m sqlalchemy_exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 2343\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m sqlalchemy_exception\u001B[38;5;241m.\u001B[39mwith_traceback(exc_info[\u001B[38;5;241m2\u001B[39m]) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m   2344\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2345\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m exc_info[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1969\u001B[0m, in \u001B[0;36mConnection._exec_single_context\u001B[1;34m(self, dialect, context, statement, parameters)\u001B[0m\n\u001B[0;32m   1967\u001B[0m                 \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m   1968\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evt_handled:\n\u001B[1;32m-> 1969\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdialect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_execute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1970\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstr_statement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meffective_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\n\u001B[0;32m   1971\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1973\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_events \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine\u001B[38;5;241m.\u001B[39m_has_events:\n\u001B[0;32m   1974\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch\u001B[38;5;241m.\u001B[39mafter_cursor_execute(\n\u001B[0;32m   1975\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1976\u001B[0m         cursor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1980\u001B[0m         context\u001B[38;5;241m.\u001B[39mexecutemany,\n\u001B[0;32m   1981\u001B[0m     )\n",
      "File \u001B[1;32mc:\\users\\mikes\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sqlalchemy\\engine\\default.py:922\u001B[0m, in \u001B[0;36mDefaultDialect.do_execute\u001B[1;34m(self, cursor, statement, parameters, context)\u001B[0m\n\u001B[0;32m    921\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_execute\u001B[39m(\u001B[38;5;28mself\u001B[39m, cursor, statement, parameters, context\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 922\u001B[0m     \u001B[43mcursor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstatement\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mOperationalError\u001B[0m: (sqlite3.OperationalError) no such column: VWAP_D\n[SQL: select Open ,High ,Low ,Close ,\"Adj Close\" ,Volume ,MACD_12_26_9 ,MACDh_12_26_9 ,MACDs_12_26_9 ,RSI_14 ,\"BBL_5_2.0\" ,\"BBM_5_2.0\" ,\"BBU_5_2.0\" ,\"BBB_5_2.0\" ,\"BBP_5_2.0\" ,OBV ,SMA_20 ,EMA_50 ,STOCHk_14_3_3 ,STOCHd_14_3_3 ,ADX_14 ,DMP_14 ,DMN_14 ,AD ,STDEV_30 ,VWAP_D ,PV_DERIVATIVE ,Y_CLOSE5_MIN from STOCK_DAILY WHERE ticker='TSLA']\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import torch as T\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "\n",
    "\n",
    "class SqliteDataSet(Dataset):\n",
    "    def __init__(self,\n",
    "                 sqlite_rul='sqlite:///D:\\\\sqlite\\\\data\\\\finance.db',\n",
    "                 query='select * from STOCK_DAILY',\n",
    "                 transform=None):\n",
    "\n",
    "        self.engine = sqlalchemy.create_engine('sqlite:///D:\\\\sqlite\\\\data\\\\finance.db')\n",
    "        self.transform = transform\n",
    "        self.result_set = pd.read_sql_query(query,self.engine.connect()).dropna()  \n",
    "        self.result_set.reset_index(drop=True,inplace=True),\n",
    "        X_columns=['Open','High' ,'Low' ,'Close','Adj Close' ,'Volume' ,'MACD_12_26_9' ,'MACDh_12_26_9' ,'MACDs_12_26_9','RSI_14' ,'BBL_5_2.0' ,'BBM_5_2.0' ,'BBU_5_2.0' ,'BBB_5_2.0' ,'BBP_5_2.0' ,'OBV' ,'SMA_20' ,'EMA_50' ,'STOCHk_14_3_3' ,'STOCHd_14_3_3' ,'ADX_14' ,'DMP_14' ,'DMN_14' ,'AD' ,'STDEV_30' ,'VWAP_D' ,'PV_DERIVATIVE' ]\n",
    "        self.result_set['rate'] = ( self.result_set['Y_CLOSE5_MIN'] - self.result_set['Close'] ) / self.result_set['Close'] * 100\n",
    "        sd_scaler = StandardScaler()\n",
    "        self.result_set[X_columns] = sd_scaler.fit_transform(self.result_set[X_columns])\n",
    "\n",
    "        self.length = self.result_set.shape[0]\n",
    "        # from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "        # mapper = DataFrameMapper([(df.columns, StandardScaler())])\n",
    "        # scaled_features = mapper.fit_transform(df.copy(), 4)\n",
    "        # scaled_features_df = pd.DataFrame(scaled_features, index=df.index, columns=df.columns)\n",
    "\n",
    "    def __getitem__(self, index) -> T.Tuple[T.Tensor,int]:\n",
    "        data = self.result_set.loc[index]\n",
    "        # rate = ( data['Y_CLOSE5_MAX'] - data['Close'] ) / data['Close'] * 100\n",
    "        rate = data['rate']\n",
    "        x = T.tensor(data.drop(['Y_CLOSE5_MIN','rate'])).to(T.float32)        \n",
    "        if rate > 5:\n",
    "            y = 4\n",
    "        elif 2 < rate < 5:\n",
    "            y = 3\n",
    "        elif rate < -5:\n",
    "            y = 0\n",
    "        elif -5 <= rate < -2:\n",
    "            y = 1\n",
    "        else:\n",
    "            y = 2         \n",
    "       \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "device = T.device('cuda' if T.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# Hyper-parameters\n",
    "input_size = 27\n",
    "hidden_size = 200\n",
    "num_classes = 5\n",
    "num_epochs = 20\n",
    "batch_size = 3\n",
    "learning_rate = 0.01\n",
    "\n",
    "query =r\"\"\"select Open ,High ,Low ,Close ,\"Adj Close\" ,Volume ,MACD_12_26_9 ,MACDh_12_26_9 ,MACDs_12_26_9 ,RSI_14 ,\"BBL_5_2.0\" ,\"BBM_5_2.0\" ,\"BBU_5_2.0\" ,\"BBB_5_2.0\" ,\"BBP_5_2.0\" ,OBV ,SMA_20 ,EMA_50 ,STOCHk_14_3_3 ,STOCHd_14_3_3 ,ADX_14 ,DMP_14 ,DMN_14 ,AD ,STDEV_30 ,VWAP_D ,PV_DERIVATIVE ,Y_CLOSE5_MIN from STOCK_DAILY WHERE ticker='TSLA'\"\"\"\n",
    "\n",
    "print(query)\n",
    "\n",
    "all_dataset = SqliteDataSet(query=query)\n",
    "\n",
    "print(all_dataset.__len__())\n",
    "\n",
    "train_set, test_set = T.utils.data.random_split(all_dataset,[650,49])\n",
    "\n",
    "# print(all_dataset.__getitem__(0))\n",
    "\n",
    "# test_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "#                                           train=False,\n",
    "#                                           transform=transforms.ToTensor())\n",
    "# \n",
    "# # Data loader\n",
    "train_loader = T.utils.data.DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "verify_loader = T.utils.data.DataLoader(dataset=train_set,\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=True)\n",
    "# \n",
    "test_loader = T.utils.data.DataLoader(dataset=test_set,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "example_targets, example_data\n",
    "\n",
    "# examples = iter(train_loader)\n",
    "# example_data, example_targets = next(examples)\n",
    "# print(example_data)\n",
    "\n",
    "# for i in range(6):\n",
    "#     plt.subplot(2,3,i+1)\n",
    "#     plt.imshow(example_data[i][0], cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out put sample:  tensor([[ 0.2274, -0.1588, -0.3679,  0.0613, -4.6641],\n",
      "        [-0.3161,  0.2043,  0.5861, -1.0795, -1.8019],\n",
      "        [ 0.2276, -0.1106, -0.0726, -0.1885, -1.1172]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[-0.3345, -1.7054,  0.9991, -0.2576, -5.0325],\n",
      "        [ 0.6915, -0.5253,  0.4165, -1.3155, -2.3044],\n",
      "        [-0.4189, -2.2684,  1.3101, -0.2945, -6.9314]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.4725,  0.2498,  0.4073, -0.3503, -1.6945],\n",
      "        [ 0.3945,  0.1278,  0.2116, -0.4425, -1.0444],\n",
      "        [ 0.6020,  0.0919,  0.6477, -0.7092, -2.8115]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.3400,  0.0745,  0.3377, -0.4756, -0.8104],\n",
      "        [ 0.3400,  0.0745,  0.3377, -0.4756, -0.8104],\n",
      "        [ 0.4748, -0.2900,  0.7620,  0.2866, -2.5295]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.5347,  0.1371,  0.3246, -0.6924, -1.0579],\n",
      "        [ 0.9639,  0.5974,  0.5713, -1.8596, -3.1302],\n",
      "        [ 0.1220, -0.2010,  2.1841, -2.1425, -4.5896]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.5249,  0.1150,  0.3617, -0.6186, -1.1910],\n",
      "        [ 0.4823, -0.0135,  1.0817, -0.8151, -1.6880],\n",
      "        [ 0.5249,  0.1150,  0.3617, -0.6186, -1.1910]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.5561,  0.0233,  0.4196, -0.5627, -1.3106],\n",
      "        [ 0.7435, -0.0545,  0.2005, -0.9929, -1.4670],\n",
      "        [ 0.7171, -0.0435,  0.2314, -0.9323, -1.4449]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.3803,  0.1023,  0.5000, -0.7825, -1.7740],\n",
      "        [ 0.5554,  0.1836,  0.3954, -0.6402, -1.4690],\n",
      "        [ 0.5554,  0.1836,  0.3954, -0.6402, -1.4690]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.6485,  0.0704,  0.4538, -0.6880, -1.5422],\n",
      "        [-1.7063,  0.0955,  2.2748, -2.4171, -7.3979],\n",
      "        [ 0.6101,  0.0237,  0.5392, -0.7559, -1.7526]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[-2.7570, -0.4945,  2.9682, -1.4377, -9.4663],\n",
      "        [ 1.2381,  0.0595, -0.3093, -1.2549, -2.0380],\n",
      "        [ 0.6717,  0.0844,  0.4210, -0.6981, -1.5341]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.5372,  0.1283,  0.4681, -0.5650, -1.6602],\n",
      "        [ 0.2336,  0.2929,  0.8143, -0.6214, -2.3189],\n",
      "        [ 2.7330,  0.2392, -2.9215, -2.8378, -2.0245]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[-2.1941, -0.6670,  2.0637, -0.5598, -3.6362],\n",
      "        [ 0.6605,  0.0702,  0.4161, -0.6034, -1.6116],\n",
      "        [ 1.2375, -0.6795, -0.7459, -2.1549, -2.8351]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.5874,  0.0224,  0.4977, -0.6103, -1.5127],\n",
      "        [ 0.5874,  0.0224,  0.4977, -0.6103, -1.5127],\n",
      "        [-0.6752, -0.7198,  1.9409, -1.3116, -3.3971]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.2706,  0.0403,  0.5864, -0.5714, -2.0474],\n",
      "        [ 0.6522,  0.1030,  0.4063, -0.6258, -1.6083],\n",
      "        [ 0.6522,  0.1030,  0.4063, -0.6258, -1.6083]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.6758,  0.0245,  0.4334, -0.6924, -1.4614],\n",
      "        [ 0.1084, -0.1997,  0.9007, -0.7671, -2.0672],\n",
      "        [ 0.6758,  0.0245,  0.4334, -0.6924, -1.4614]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.4386,  0.0673,  0.4794, -0.6792, -1.6844],\n",
      "        [-1.3958,  0.5236,  1.1472, -1.1653, -3.4949],\n",
      "        [-1.3434,  0.6809,  1.2023, -1.3596, -3.9838]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.4248,  0.0938,  0.4430, -0.5708, -1.7735],\n",
      "        [ 0.6838,  0.0934,  0.3770, -0.6107, -1.6260],\n",
      "        [-0.1198,  0.0909,  0.5736, -0.4917, -2.0931]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[  0.7209,   0.0728,   0.3335,  -0.6232,  -1.5474],\n",
      "        [  0.7209,   0.0728,   0.3335,  -0.6232,  -1.5474],\n",
      "        [  3.2119,  -0.9192,  -4.9952, -10.4769,  -8.2314]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.6925,  0.0508,  0.3251, -0.5415, -1.5325],\n",
      "        [ 0.6925,  0.0508,  0.3251, -0.5415, -1.5325],\n",
      "        [ 0.6925,  0.0508,  0.3251, -0.5415, -1.5325]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.7584,  0.0725,  0.3373, -0.7042, -1.5312],\n",
      "        [ 0.6424,  0.0393,  0.4255, -0.7481, -1.6193],\n",
      "        [-0.1425, -0.1856,  1.0222, -1.0454, -2.2157]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.6896,  0.1373,  0.3053, -0.5897, -1.6024],\n",
      "        [ 0.6896,  0.1373,  0.3053, -0.5897, -1.6024],\n",
      "        [ 0.1873,  0.0961,  0.5175, -0.6115, -1.7148]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.7211,  0.1230,  0.3102, -0.6397, -1.5849],\n",
      "        [ 0.7211,  0.1230,  0.3102, -0.6397, -1.5849],\n",
      "        [-0.0169,  0.0404,  0.6828, -0.6915, -1.7953]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.1393,  0.0595,  0.4315, -0.4934, -1.5858],\n",
      "        [ 0.7103,  0.1819,  0.1886, -0.5533, -1.5311],\n",
      "        [ 0.7103,  0.1819,  0.1886, -0.5533, -1.5311]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.8053,  0.0962,  0.2655, -0.6455, -1.6213],\n",
      "        [ 0.8053,  0.0962,  0.2655, -0.6455, -1.6213],\n",
      "        [-0.0111,  0.0219,  0.7233, -0.8046, -2.0400]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[-0.6740,  0.0509,  0.5810, -0.7546, -3.2358],\n",
      "        [ 0.0284, -0.0424,  0.6185, -0.5156, -2.0831],\n",
      "        [ 0.8052,  0.0689,  0.2402, -0.5776, -1.6079]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.7906,  0.1811,  0.1846, -0.6442, -1.5791],\n",
      "        [-1.3549, -0.0589,  1.0422, -0.2577, -3.0139],\n",
      "        [ 0.7906,  0.1811,  0.1846, -0.6442, -1.5791]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[-0.6203, -0.0136,  0.9331, -0.7853, -2.0365],\n",
      "        [ 0.8680,  0.0722,  0.2387, -0.7216, -1.5436],\n",
      "        [ 0.8680,  0.0722,  0.2387, -0.7216, -1.5436]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.7971,  0.1472,  0.2662, -0.7543, -1.5462],\n",
      "        [ 0.7971,  0.1472,  0.2662, -0.7543, -1.5462],\n",
      "        [ 0.7971,  0.1472,  0.2662, -0.7543, -1.5462]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.6983,  0.2218,  0.2738, -0.6754, -1.6093],\n",
      "        [ 0.6983,  0.2218,  0.2738, -0.6754, -1.6093],\n",
      "        [ 0.5926,  0.2138,  0.3302, -0.6844, -1.6623]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.8041,  0.0661,  0.2388, -0.5980, -1.5711],\n",
      "        [-2.5547, -0.1973,  1.6669, -0.3158, -3.1015],\n",
      "        [ 0.8041,  0.0661,  0.2388, -0.5980, -1.5711]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.7440,  0.1809,  0.2434, -0.6183, -1.6539],\n",
      "        [ 0.7440,  0.1809,  0.2434, -0.6183, -1.6539],\n",
      "        [ 1.3491,  1.5224, -2.3321, -4.3786, -8.3547]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.8226,  0.1694,  0.1456, -0.6620, -1.5131],\n",
      "        [ 0.8226,  0.1694,  0.1456, -0.6620, -1.5131],\n",
      "        [ 0.8226,  0.1694,  0.1456, -0.6620, -1.5131]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.7947,  0.1467,  0.1175, -0.5249, -1.5477],\n",
      "        [ 0.7947,  0.1467,  0.1175, -0.5249, -1.5477],\n",
      "        [-1.3515, -0.1388,  0.7594, -0.0208, -1.6509]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.7735,  0.0897,  0.3502, -0.7469, -1.5829],\n",
      "        [ 0.7735,  0.0897,  0.3502, -0.7469, -1.5829],\n",
      "        [-4.3223, -0.6939,  2.6771, -0.4892, -2.4687]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.8350,  0.2135,  0.1973, -0.7728, -1.6046],\n",
      "        [-2.6678,  0.0908,  1.4505, -0.4913, -2.3745],\n",
      "        [ 0.8350,  0.2135,  0.1973, -0.7728, -1.6046]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.7868,  0.1282,  0.2793, -0.6681, -1.6605],\n",
      "        [ 0.7868,  0.1282,  0.2793, -0.6681, -1.6605],\n",
      "        [ 0.7868,  0.1282,  0.2793, -0.6681, -1.6605]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.8700,  0.0822,  0.1766, -0.6073, -1.6160],\n",
      "        [-1.0235, -6.3649, -4.4193,  2.1635, -2.1379],\n",
      "        [ 0.8700,  0.0822,  0.1766, -0.6073, -1.6160]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.6890,  0.1691,  0.3083, -0.6417, -1.6229],\n",
      "        [ 0.6890,  0.1691,  0.3083, -0.6417, -1.6229],\n",
      "        [ 0.6890,  0.1691,  0.3083, -0.6417, -1.6229]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.7412,  0.1476,  0.2193, -0.5803, -1.5888],\n",
      "        [ 0.7412,  0.1476,  0.2193, -0.5803, -1.5888],\n",
      "        [ 0.7412,  0.1476,  0.2193, -0.5803, -1.5888]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "out put sample:  tensor([[ 0.7610,  0.1973,  0.1947, -0.6430, -1.5902],\n",
      "        [-8.2996,  0.7520,  2.3643, -2.4280, -4.6552],\n",
      "        [ 0.7610,  0.1973,  0.1947, -0.6430, -1.5902]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "##Fully connected neural network with one hidden layer\n",
    "# class YhatCrossEntropyLoss(torch.CrossEntropyLoss):\n",
    "#     def __init__(self)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.nn_block1 = nn.Sequential(\n",
    "            nn.Linear(input_size, 200),\n",
    "            nn.ReLU()     ,\n",
    "            nn.Linear(200, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, num_classes),\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.nn_block1(x)\n",
    "\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "# weight = torch.tensor([10.,4.,1.2,1.1,0.9])\n",
    "weight = torch.tensor([1.,1.,1.,1.,1.])\n",
    "criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (databatch, labels) in enumerate(train_loader):\n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        databatch = databatch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass and loss calculation\n",
    "        outputs = model(databatch)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # for p in model.parameters():\n",
    "        #     p.register_hook(lambda grad: torch.clamp(grad, -1, 1 ))\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0, norm_type=2)\n",
    "\n",
    "        optimizer.step()\n",
    "       \n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            ##print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "            print(\"out put sample: \", outputs)\n",
    "            # print(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T02:34:31.181391100Z",
     "start_time": "2024-01-07T02:34:13.388349700Z"
    }
   },
   "id": "97a703ab882a5239"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "torch.save(model.state_dict(), \"./tamed/M1_min5_46v_20240106.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T02:42:56.322298300Z",
     "start_time": "2024-01-07T02:42:56.306627Z"
    }
   },
   "id": "31d0676614dc2870"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "tensor([1]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([2]) tensor([2])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([4]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([2]) tensor([2])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([3]) tensor([2])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([1]) tensor([2])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([2])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "Accuracy of the network on the 49 test images: 38.775510204081634 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model: we don't need to compute gradients\n",
    "import torch as T\n",
    "with T.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = len(test_loader.dataset)\n",
    "    print(n_samples)\n",
    "\n",
    "    for d_data, labels in test_loader:\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(d_data)\n",
    "\n",
    "        # max returns (output_value ,index)\n",
    "        _, predicted = T.max(outputs, 1)\n",
    "        print(labels,predicted)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the {n_samples} test images: {100*acc} %')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T02:46:59.810217400Z",
     "start_time": "2024-01-07T02:46:59.746575900Z"
    }
   },
   "id": "126c1d56a876585f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x0000012D74DEA580>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-31T02:10:15.414208100Z",
     "start_time": "2023-12-31T02:10:15.398577200Z"
    }
   },
   "id": "99ff880c6d7a0664"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "l_model.load_state_dict(torch.load('./tamed/M1_min5_46v_20240106.pt'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T02:52:53.235879300Z",
     "start_time": "2024-01-07T02:52:53.183421400Z"
    }
   },
   "id": "58e2922083a2947d"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "tensor([1]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([2]) tensor([2])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([4]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([2]) tensor([2])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([3]) tensor([2])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([1]) tensor([2])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([2]) tensor([2])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([1]) tensor([0])\n",
      "tensor([2]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([0]) tensor([0])\n",
      "tensor([3]) tensor([0])\n",
      "Accuracy of the network on the 49 test images: 38.775510204081634 %\n"
     ]
    }
   ],
   "source": [
    "l_model.eval()\n",
    "# Test the model: we don't need to compute gradients\n",
    "import torch as T\n",
    "with T.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = len(test_loader.dataset)\n",
    "    print(n_samples)\n",
    "\n",
    "    for d_data, labels in test_loader:\n",
    "\n",
    "        labels = labels.to(device)\n",
    "        outputs = l_model(d_data)\n",
    "\n",
    "        # max returns (output_value ,index)\n",
    "        _, predicted = T.max(outputs, 1)\n",
    "        print(labels,predicted)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the {n_samples} test images: {100*acc} %')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T03:01:04.590793500Z",
     "start_time": "2024-01-07T03:01:04.529697300Z"
    }
   },
   "id": "7f690078160077b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "26fe37a3ff57f8f7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
